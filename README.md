# ğŸ¤– RAG QA Bot with OpenAI, Pinecone & LlamaIndex

This is a modular **Retrieval-Augmented Generation (RAG)** chatbot that allows users to query information from custom **PDF documents** via a simple **Streamlit interface**. It uses:

- **OpenAI** (for embedding & answering)
- **LlamaIndex** (for document indexing & querying)
- **Pinecone** (for storing vector embeddings)
- **Streamlit** (for the frontend chatbot interface)

---

## ğŸ—‚ï¸ Project Structure

rag-qa-bot/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ loader.py # Loads PDF from disk
â”‚ â”œâ”€â”€ Config.py # config setup (OpenAI / HuggingFace)
â”‚ â”œâ”€â”€ index_builder.py # Builds or loads the vector index
â”‚ â”œâ”€â”€ query_engine.py # Prepares the query engine
â”‚ â”œâ”€â”€ chatbot_ui.py # Streamlit chatbot interface
â”‚
â”œâ”€â”€ business_faq.pdf # ğŸ“„ Sample PDF document
â”œâ”€â”€ chatbot_app.py # ğŸ” Streamlit UI
â”œâ”€â”€ main.py # ğŸ” Streamlit entry point
â”œâ”€â”€ .env # ğŸ”‘ API credentials (not shared)
â”œâ”€â”€ .gitignore # Git ignored files
â””â”€â”€ README.md # This file



---

## ğŸ”§ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/rag-qa-bot.git
cd rag-qa-bot
```

### 2. Set up a virtual environment 

```bash
python -m venv env310
source env310/bin/activate  # macOS/Linux
env310\Scripts\activate     # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Add environment variables

```bash

OPENAI_API_KEY=your-openai-key
PINECONE_API_KEY=your-pinecone-key
PINECONE_ENV=your-pinecone-region
PINECONE_INDEX_NAME=your-index-name

```

### 5. Run the app

```bash
streamlit run main.py
```


## Project Link : 